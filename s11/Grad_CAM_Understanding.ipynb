{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3o71/fmgbghUNyH/P02Zi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phaninandula/ERA-Session11/blob/main/Grad_CAM_Understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRAD-CAM STEPS\n",
        "Steps of Grad-CAM\n",
        "1. Capture the output of the last convolution layer of the network.\n",
        "2. Take gradient of last convolution layer with respect to prediction probability. (We can take predictions with respect to any class we want. In our case, we'll take prediction with the highest probability. We can look at other probabilities as well)\n",
        "3. Average gradients calculated in the previous step at axis which has the same dimension as output channels of last convolution layer. The output of this step will be 1D array that has the same numbers as that of output channels of the last convolution layer.\n",
        "4. Multiply convolution layer output with averaged gradients from the previous step at output channel level, i.e. first channel output should be multiplied with first averaged value, second should be multiplied with the second value, and so on.\n",
        "5. Average output from the previous step at channel level to create 2D heatmap that has the same dimension as that of image.\n",
        "6. Normalize heatmap (Optional step but recommended as it helps improve results)."
      ],
      "metadata": {
        "id": "B2bwUe00gtzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch Version : {}\".format(torch.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhSM9t4HgtD8",
        "outputId": "7d598a3a-3fa1-4c77-89a9-10c56de79fbb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version : 2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = torch.tensor(X_train, dtype=torch.float32),\\\n",
        "                                   torch.tensor(X_test, dtype=torch.float32),\\\n",
        "                                   torch.tensor(Y_train, dtype=torch.long),\\\n",
        "                                   torch.tensor(Y_test, dtype=torch.long)\n",
        "\n",
        "X_train, X_test = X_train.reshape(-1,1,28,28), X_test.reshape(-1,1,28,28)\n",
        "\n",
        "X_train, X_test = X_train/255.0, X_test/255.0\n",
        "\n",
        "classes =  Y_train.unique()\n",
        "class_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "mapping = dict(zip(classes.numpy(), class_labels))\n",
        "\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuYFNvWegtAR",
        "outputId": "c278c1bc-7977-4625-850c-4260c6ba3330"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 1, 28, 28]),\n",
              " torch.Size([10000, 1, 28, 28]),\n",
              " torch.Size([60000]),\n",
              " torch.Size([10000]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "KMTKOWaRhWTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "test_dataset  = TensorDataset(X_test , Y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "1WTRGtglgs9Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ],
      "metadata": {
        "id": "iY58luYahZYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNetModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNetModel,self).__init__()\n",
        "    self.seq = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=48,kernel_size=(3,3), padding = 'same', bias=False),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Conv2d(in_channels=48,out_channels=32,kernel_size=(3,3), padding = 'same', bias=False),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Conv2d(in_channels=32,out_channels=16,kernel_size=(3,3), padding = 'same', bias=False),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(16*28*28, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x_batch):\n",
        "    return self.seq(x_batch)\n",
        "\n",
        "convnet = ConvNetModel()\n",
        "convnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irtuBtKlgs6m",
        "outputId": "82ada1da-96d7-4852-e61a-f6d93b72ea85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNetModel(\n",
              "  (seq): Sequential(\n",
              "    (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
              "    (5): ReLU()\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=12544, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Network"
      ],
      "metadata": {
        "id": "42CUK-n1jPDM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a69RWi4Igm2H"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "def CalcValLoss(model, loss_func, val_loader):\n",
        "    with torch.no_grad(): ## Prevents calculation of gradients\n",
        "        val_losses = []\n",
        "        for X_batch, Y_batch in val_loader:\n",
        "            preds = model(X_batch)\n",
        "            loss = loss_func(preds, Y_batch)\n",
        "            val_losses.append(loss)\n",
        "        print(\"Valid CategoricalCrossEntropy : {:.3f}\".format(torch.tensor(val_losses).mean()))\n",
        "\n",
        "def MakePredictions(model, loader):\n",
        "    preds, Y_shuffled = [], []\n",
        "    for X_batch, Y_batch in loader:\n",
        "        preds.append(model(X_batch))\n",
        "        Y_shuffled.append(Y_batch)\n",
        "\n",
        "    preds = torch.cat(preds).argmax(axis=-1)\n",
        "    Y_shuffled = torch.cat(Y_shuffled)\n",
        "    return Y_shuffled, preds\n",
        "\n",
        "def TrainModelInBatchesV1(model, loss_func, optimizer, train_loader, val_loader, epochs=5):\n",
        "    for i in range(epochs):\n",
        "        losses = [] ## Record loss of each batch\n",
        "        for X_batch, Y_batch in tqdm(train_loader):\n",
        "            preds = model(X_batch) ## Make Predictions by forward pass through network\n",
        "\n",
        "            loss = loss_func(preds, Y_batch) ## Calculate Loss\n",
        "            losses.append(loss) ## Record Loss\n",
        "\n",
        "            optimizer.zero_grad() ## Zero weights before calculating gradients\n",
        "            loss.backward() ## Calculate Gradients\n",
        "            optimizer.step() ## Update Weights\n",
        "\n",
        "        print(\"Train CategoricalCrossEntropy : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        CalcValLoss(model, loss_func, val_loader)\n",
        "\n",
        "        Y_test_shuffled, test_preds = MakePredictions(model, val_loader)\n",
        "        val_acc = accuracy_score(Y_test_shuffled, test_preds)\n",
        "        print(\"Val  Accuracy : {:.3f}\".format(val_acc))\n",
        "        #gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, RMSprop, Adam\n",
        "\n",
        "#torch.manual_seed(42) ##For reproducibility.This will make sure that same random weights are initialized each time.\n",
        "epochs = 3\n",
        "learning_rate = torch.tensor(1e-3) # 0.001\n",
        "\n",
        "conv_net = ConvNetModel()\n",
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(params=conv_net.parameters(), lr=learning_rate)\n",
        "\n",
        "TrainModelInBatchesV1(conv_net, cross_entropy_loss, optimizer, train_loader, test_loader,epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCrScYAOjRlB",
        "outputId": "abe90b49-101c-420b-80da-da003551ba9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 577/938 [02:06<26:35,  4.42s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grad-CAM implementation"
      ],
      "metadata": {
        "id": "Eyq9KNFfjcb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Capture Output Of Last Convolution Layer"
      ],
      "metadata": {
        "id": "NAO2bKFmjlIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(conv_net.children())"
      ],
      "metadata": {
        "id": "cx-u_j6-jRhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(conv_net.children())[0]"
      ],
      "metadata": {
        "id": "dn53OGVFjRdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv_layer_Selection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Conv_layer_Selection,self).__init__()\n",
        "    self.layers = list(list(conv_net.children())[0].children())\n",
        "\n",
        "  def forward(self,layer_num,X_batch):\n",
        "    x = self.layers[0](X_batch)\n",
        "    conv_layer_output = None\n",
        "\n",
        "    for i,layer in enumerate(self.layers):\n",
        "      x = layer(x) # helps to pass the data through the layers till it reaches the layer_num of interest and stops\n",
        "      if i == layer_num:\n",
        "        self.conv_layer_output = x\n",
        "    return x"
      ],
      "metadata": {
        "id": "JYso_zY1jRZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passing one random image through the Trained Network and"
      ],
      "metadata": {
        "id": "E0rIZyhonBeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "conv_model = LastConvLayerModel()\n",
        "idx = np.random.choice(range(10000))\n",
        "pred = conv_model(X_test[idx:idx+1],layer_num=)\n",
        "\n",
        "F.softmax(pred, dim=-1).argmax(), F.softmax(pred, dim=-1).max()"
      ],
      "metadata": {
        "id": "VFkkOFIekRyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_model.conv_layer_output.shape # Should have 16 filters at the end"
      ],
      "metadata": {
        "id": "A1goW8e5kRu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0EHZDUNkRrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAZcToFvkRoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}