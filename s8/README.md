
## Quick Read
| Type| Topic        | Remarks           | 
|:------------- | :------------- |:-------------|
|Normalization| Batch Normalization| <ul><li>No of params in Batch Normalization=2XNo of kernals</li></ul>|
|Normalization| Layer Normalization| <ul><li>No of params in Layer Normalization=2XNo of images in batch</li><li>Useful incase of the NLp as a layer indicates the whole sentense info</li></ul>|
|Normalization| Group Normalization| <ul><li>No of params in Group Normalization=2XNo of groups defined</li></ul>|


##### Dropout works on the neuron level ,Incase of 
##### L1,L2 works for fully connected layers
